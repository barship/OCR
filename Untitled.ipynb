{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "#-*- coding: utf-8 -*-\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "import random\n",
    "import tensorflow.contrib.slim as slim\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tensorflow.python.ops import control_flow_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('Training a chinese write char recognition')\n",
    "logger.setLevel(logging.INFO)\n",
    "#formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入参数解析\n",
    "tf.app.flags.DEFINE_boolean('random_flip_up_down', False, \"Whether to random flip up down\")\n",
    "tf.app.flags.DEFINE_boolean('random_brightness', True, \"whether to adjust brightness\")\n",
    "tf.app.flags.DEFINE_boolean('random_contrast', True, \"whether to random constrast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_integer('charset_size', 4363, \"Choose the first `charset_size` characters only.\")\n",
    "tf.app.flags.DEFINE_integer('image_size', 64, \"Needs to provide same value as in training.\")\n",
    "tf.app.flags.DEFINE_boolean('gray', True, \"whether to change the rbg to gray\")\n",
    "tf.app.flags.DEFINE_integer('max_steps', 16002, 'the max training steps ')\n",
    "tf.app.flags.DEFINE_integer('eval_steps', 100, \"the step num to eval\")\n",
    "tf.app.flags.DEFINE_integer('save_steps', 500, \"the steps to save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_string('checkpoint_dir', 'checkpoint/', 'the checkpoint dir')\n",
    "tf.app.flags.DEFINE_string('train_data_dir', 'dataset/train/', 'the train dataset dir')\n",
    "tf.app.flags.DEFINE_string('test_data_dir', 'dataset/test/', 'the test dataset dir')\n",
    "#tf.app.flags.DEFINE_string('log_dir', './log', 'the logging dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_boolean('restore', False, 'whether to restore from checkpoint')\n",
    "tf.app.flags.DEFINE_boolean('epoch', 1, 'Number of epoches')\n",
    "tf.app.flags.DEFINE_integer('batch_size', 128, 'Validation batch size')\n",
    "tf.app.flags.DEFINE_string('mode', 'validation', 'Running mode. One of {\"train\", \"valid\", \"test\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.85)\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIterator:\n",
    " def __init__(self, data_dir):\n",
    " # Set FLAGS.charset_size to a small value if available computation power is limited.\n",
    " truncate_path = data_dir + ('%05d' % FLAGS.charset_size)\n",
    " print(truncate_path)\n",
    " # 遍历训练集所有图像的路径，存储在image_names内\n",
    " self.image_names = []\n",
    " for root, sub_folder, file_list in os.walk(data_dir):\n",
    " if root < truncate_path:\n",
    " self.image_names += [os.path.join(root, file_path) for file_path in file_list]\n",
    " random.shuffle(self.image_names) # 打乱\n",
    " # 例如image_name为./train/00001/2.png，提取00001就是其label\n",
    " self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in self.image_names]\n",
    " @property\n",
    " def size(self):\n",
    " return len(self.labels)\n",
    " @staticmethod\n",
    " def data_augmentation(images):\n",
    " # 镜像变换\n",
    " if FLAGS.random_flip_up_down:\n",
    " images = tf.image.random_flip_up_down(images)\n",
    " # 图像亮度变化\n",
    " if FLAGS.random_brightness:\n",
    " images = tf.image.random_brightness(images, max_delta=0.3)\n",
    " # 对比度变化\n",
    " if FLAGS.random_contrast:\n",
    " images = tf.image.random_contrast(images, 0.8, 1.2)\n",
    " return images\n",
    " # batch的生成\n",
    " def input_pipeline(self, batch_size, num_epochs=None, aug=False):\n",
    " # numpy array 转 tensor\n",
    " images_tensor = tf.convert_to_tensor(self.image_names, dtype=tf.string)\n",
    " labels_tensor = tf.convert_to_tensor(self.labels, dtype=tf.int64)\n",
    " # 将image_list ,label_list做一个slice处理\n",
    " input_queue = tf.train.slice_input_producer([images_tensor, labels_tensor], num_epochs=num_epochs)\n",
    " labels = input_queue[1]\n",
    " images_content = tf.read_file(input_queue[0])\n",
    " images = tf.image.convert_image_dtype(tf.image.decode_png(images_content, channels=1), tf.float32)\n",
    " if aug:\n",
    " images = self.data_augmentation(images)\n",
    " new_size = tf.constant([FLAGS.image_size, FLAGS.image_size], dtype=tf.int32)\n",
    " images = tf.image.resize_images(images, new_size)\n",
    " image_batch, label_batch = tf.train.shuffle_batch([images, labels], batch_size=batch_size, capacity=50000,\n",
    " min_after_dequeue=10000)\n",
    " # print 'image_batch', image_batch.get_shape()\n",
    " return image_batch, label_batch\n",
    "def build_graph(top_k):\n",
    " keep_prob = tf.placeholder(dtype=tf.float32, shape=[], name='keep_prob') # dropout打开概率\n",
    " images = tf.placeholder(dtype=tf.float32, shape=[None, 64, 64, 1], name='image_batch')\n",
    " labels = tf.placeholder(dtype=tf.int64, shape=[None], name='label_batch')\n",
    " is_training = tf.placeholder(dtype=tf.bool, shape=[], name='train_flag')\n",
    " with tf.device('/gpu:0'):\n",
    " # network: conv2d->max_pool2d->conv2d->max_pool2d->conv2d->max_pool2d->conv2d->conv2d->\n",
    " # max_pool2d->fully_connected->fully_connected\n",
    " #给slim.conv2d和slim.fully_connected准备了默认参数：batch_norm\n",
    " with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    " normalizer_fn=slim.batch_norm,\n",
    " normalizer_params={'is_training': is_training,'decay': 0.95}):\n",
    " conv3_1 = slim.conv2d(images, 64, [3, 3], 1, padding='SAME', scope='conv3_1')\n",
    " max_pool_1 = slim.max_pool2d(conv3_1, [2, 2], [2, 2], padding='SAME', scope='pool1')\n",
    " conv3_2 = slim.conv2d(max_pool_1, 128, [3, 3], padding='SAME', scope='conv3_2')\n",
    " max_pool_2 = slim.max_pool2d(conv3_2, [2, 2], [2, 2], padding='SAME', scope='pool2')\n",
    " conv3_3 = slim.conv2d(max_pool_2, 256, [3, 3], padding='SAME', scope='conv3_3')\n",
    " max_pool_3 = slim.max_pool2d(conv3_3, [2, 2], [2, 2], padding='SAME', scope='pool3')\n",
    " conv3_4 = slim.conv2d(max_pool_3, 512, [3, 3], padding='SAME', scope='conv3_4')\n",
    " conv3_5 = slim.conv2d(conv3_4, 512, [3, 3], padding='SAME', scope='conv3_5')\n",
    " max_pool_4 = slim.max_pool2d(conv3_5, [2, 2], [2, 2], padding='SAME', scope='pool4')\n",
    " flatten = slim.flatten(max_pool_4)\n",
    " fc1 = slim.fully_connected(slim.dropout(flatten, keep_prob), 1024,\n",
    " activation_fn=tf.nn.relu, scope='fc1')\n",
    " logits = slim.fully_connected(slim.dropout(fc1, keep_prob), FLAGS.charset_size, activation_fn=None,\n",
    " scope='fc2')\n",
    " # 因为我们没有做热编码，所以使用sparse_softmax_cross_entropy_with_logits\n",
    " loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    " accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, 1), labels), tf.float32))\n",
    " # update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    " # if update_ops:\n",
    " # updates = tf.group(*update_ops)\n",
    " # loss = control_flow_ops.with_dependencies([updates], loss)\n",
    " #\n",
    " # global_step = tf.get_variable(\"step\", [], initializer=tf.constant_initializer(0.0), trainable=False)\n",
    " # optimizer = tf.train.AdamOptimizer(learning_rate=0.1)\n",
    " # train_op = slim.learning.create_train_op(loss, optimizer, global_step=global_step)\n",
    " global_step = tf.get_variable(\"step\", [], initializer=tf.constant_initializer(0.0), trainable=False)\n",
    " optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    " train_op = slim.learning.create_train_op(loss, optimizer, global_step=global_step)\n",
    " update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    " if update_ops:\n",
    " updates = tf.group(*update_ops)\n",
    " train_op = control_flow_ops.with_dependencies([updates], train_op)\n",
    " probabilities = tf.nn.softmax(logits)\n",
    " # 绘制loss accuracy曲线\n",
    " tf.summary.scalar('loss', loss)\n",
    " tf.summary.scalar('accuracy', accuracy)\n",
    " merged_summary_op = tf.summary.merge_all()\n",
    " # 返回top k 个预测结果及其概率；返回top K accuracy\n",
    " predicted_val_top_k, predicted_index_top_k = tf.nn.top_k(probabilities, k=top_k)\n",
    " accuracy_in_top_k = tf.reduce_mean(tf.cast(tf.nn.in_top_k(probabilities, labels, top_k), tf.float32))\n",
    " return {'images': images,\n",
    " 'labels': labels,\n",
    " 'keep_prob': keep_prob,\n",
    " 'top_k': top_k,\n",
    " 'global_step': global_step,\n",
    " 'train_op': train_op,\n",
    " 'loss': loss,\n",
    " 'is_training': is_training,\n",
    " 'accuracy': accuracy,\n",
    " 'accuracy_top_k': accuracy_in_top_k,\n",
    " 'merged_summary_op': merged_summary_op,\n",
    " 'predicted_distribution': probabilities,\n",
    " 'predicted_index_top_k': predicted_index_top_k,\n",
    " 'predicted_val_top_k': predicted_val_top_k}\n",
    "def train():\n",
    " print('Begin training')\n",
    " # 填好数据读取的路径\n",
    " train_feeder = DataIterator(data_dir='dataset/train/')\n",
    " test_feeder = DataIterator(data_dir='dataset/test/')\n",
    " model_name = 'chinese-rec-model'\n",
    " with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True)) as sess:\n",
    " # batch data 获取\n",
    " train_images, train_labels = train_feeder.input_pipeline(batch_size=FLAGS.batch_size, aug=True)\n",
    " test_images, test_labels = test_feeder.input_pipeline(batch_size=FLAGS.batch_size)\n",
    " graph = build_graph(top_k=1) # 训练时top k = 1\n",
    " saver = tf.train.Saver()\n",
    " sess.run(tf.global_variables_initializer())\n",
    " # 设置多线程协调器\n",
    " coord = tf.train.Coordinator()\n",
    " threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    " train_writer = tf.summary.FileWriter(FLAGS.log_dir + 'train', sess.graph)\n",
    " test_writer = tf.summary.FileWriter(FLAGS.log_dir + 'val')\n",
    " start_step = 0\n",
    " # 可以从某个step下的模型继续训练\n",
    " if FLAGS.restore:\n",
    " ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n",
    " if ckpt:\n",
    " saver.restore(sess, ckpt)\n",
    " print(\"restore from the checkpoint {0}\".format(ckpt))\n",
    " start_step += int(ckpt.split('-')[-1])\n",
    " logger.info(':::Training Start:::')\n",
    " try:\n",
    " i = 0\n",
    " while not coord.should_stop():\n",
    " i += 1\n",
    " start_time = time.time()\n",
    " train_images_batch, train_labels_batch = sess.run([train_images, train_labels])\n",
    " feed_dict = {graph['images']: train_images_batch,\n",
    " graph['labels']: train_labels_batch,\n",
    " graph['keep_prob']: 0.8,\n",
    " graph['is_training']: True}\n",
    " _, loss_val, train_summary, step = sess.run(\n",
    " [graph['train_op'], graph['loss'], graph['merged_summary_op'], graph['global_step']],\n",
    " feed_dict=feed_dict)\n",
    " train_writer.add_summary(train_summary, step)\n",
    " end_time = time.time()\n",
    " logger.info(\"the step {0} takes {1} loss {2}\".format(step, end_time - start_time, loss_val))\n",
    " if step > FLAGS.max_steps:\n",
    " break\n",
    " if step % FLAGS.eval_steps == 1:\n",
    " test_images_batch, test_labels_batch = sess.run([test_images, test_labels])\n",
    " feed_dict = {graph['images']: test_images_batch,\n",
    " graph['labels']: test_labels_batch,\n",
    " graph['keep_prob']: 1.0,\n",
    " graph['is_training']: False}\n",
    " accuracy_test, test_summary = sess.run([graph['accuracy'], graph['merged_summary_op']],\n",
    " feed_dict=feed_dict)\n",
    " if step > 300:\n",
    " test_writer.add_summary(test_summary, step)\n",
    " logger.info('===============Eval a batch=======================')\n",
    " logger.info('the step {0} test accuracy: {1}'\n",
    " .format(step, accuracy_test))\n",
    " logger.info('===============Eval a batch=======================')\n",
    " if step % FLAGS.save_steps == 1:\n",
    " logger.info('Save the ckpt of {0}'.format(step))\n",
    " saver.save(sess, os.path.join(FLAGS.checkpoint_dir, model_name),\n",
    " global_step=graph['global_step'])\n",
    " except tf.errors.OutOfRangeError:\n",
    " logger.info('==================Train Finished================')\n",
    " saver.save(sess, os.path.join(FLAGS.checkpoint_dir, model_name), global_step=graph['global_step'])\n",
    " finally:\n",
    " # 达到最大训练迭代数的时候清理关闭线程\n",
    " coord.request_stop()\n",
    " coord.join(threads)\n",
    "def validation():\n",
    " print('Begin validation')\n",
    " test_feeder = DataIterator(data_dir='dataset/test/')\n",
    " final_predict_val = []\n",
    " final_predict_index = []\n",
    " groundtruth = []\n",
    " with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options,allow_soft_placement=True)) as sess:\n",
    " test_images, test_labels = test_feeder.input_pipeline(batch_size=FLAGS.batch_size, num_epochs=1)\n",
    " graph = build_graph(top_k=5)\n",
    " saver = tf.train.Saver()\n",
    " sess.run(tf.global_variables_initializer())\n",
    " sess.run(tf.local_variables_initializer()) # initialize test_feeder's inside state\n",
    " coord = tf.train.Coordinator()\n",
    " threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    " ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n",
    " if ckpt:\n",
    " saver.restore(sess, ckpt)\n",
    " print(\"restore from the checkpoint {0}\".format(ckpt))\n",
    " logger.info(':::Start validation:::')\n",
    " try:\n",
    " i = 0\n",
    " acc_top_1, acc_top_k = 0.0, 0.0\n",
    " while not coord.should_stop():\n",
    " i += 1\n",
    " start_time = time.time()\n",
    " test_images_batch, test_labels_batch = sess.run([test_images, test_labels])\n",
    " feed_dict = {graph['images']: test_images_batch,\n",
    " graph['labels']: test_labels_batch,\n",
    " graph['keep_prob']: 1.0,\n",
    " graph['is_training']: False}\n",
    " batch_labels, probs, indices, acc_1, acc_k = sess.run([graph['labels'],\n",
    " graph['predicted_val_top_k'],\n",
    " graph['predicted_index_top_k'],\n",
    " graph['accuracy'],\n",
    " graph['accuracy_top_k']], feed_dict=feed_dict)\n",
    " final_predict_val += probs.tolist()\n",
    " final_predict_index += indices.tolist()\n",
    " groundtruth += batch_labels.tolist()\n",
    " acc_top_1 += acc_1\n",
    " acc_top_k += acc_k\n",
    " end_time = time.time()\n",
    " logger.info(\"the batch {0} takes {1} seconds, accuracy = {2}(top_1) {3}(top_k)\"\n",
    " .format(i, end_time - start_time, acc_1, acc_k))\n",
    " except tf.errors.OutOfRangeError:\n",
    " logger.info('==================Validation Finished================')\n",
    " acc_top_1 = acc_top_1 * FLAGS.batch_size / test_feeder.size\n",
    " acc_top_k = acc_top_k * FLAGS.batch_size / test_feeder.size\n",
    " logger.info('top 1 accuracy {0} top k accuracy {1}'.format(acc_top_1, acc_top_k))\n",
    " finally:\n",
    " coord.request_stop()\n",
    " coord.join(threads)\n",
    " return {'prob': final_predict_val, 'indices': final_predict_index, 'groundtruth': groundtruth}\n",
    "#获待预测图像文件夹内的图像名字\n",
    "def get_file_list(path):\n",
    " list_name=[]\n",
    " files = os.listdir(path)\n",
    " files.sort()\n",
    " for file in files:\n",
    " file_path = os.path.join(path, file)\n",
    " list_name.append(file_path)\n",
    " return list_name\n",
    "#图像二值化，需注意待预测的汉字是黑底白字还是白底黑字\n",
    "def binary_pic(name_list):\n",
    " for image in name_list:\n",
    " temp_image = cv2.imread(image)\n",
    " #print image\n",
    " GrayImage=cv2.cvtColor(temp_image,cv2.COLOR_BGR2GRAY)\n",
    " ret,thresh1=cv2.threshold(GrayImage,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    " single_name = image.split('t/')[1]\n",
    " print(single_name)\n",
    " cv2.imwrite('ocr/tmp/'+single_name,thresh1)\n",
    "#获取汉字label映射表\n",
    "def get_label_dict():\n",
    " f=open('chinese_labels','rb')\n",
    " label_dict = pickle.load(f)\n",
    " f.close()\n",
    " return label_dict\n",
    "def inference(name_list):\n",
    " print('inference')\n",
    " image_set=[]\n",
    " # 对每张图进行尺寸标准化和归一化\n",
    " for image in name_list:\n",
    " temp_image = Image.open(image).convert('L')\n",
    " temp_image = temp_image.resize((FLAGS.image_size, FLAGS.image_size), Image.ANTIALIAS)\n",
    " temp_image = np.asarray(temp_image) / 255.0\n",
    " temp_image = temp_image.reshape([-1, 64, 64, 1])\n",
    " image_set.append(temp_image)\n",
    " # allow_soft_placement 如果你指定的设备不存在，允许TF自动分配设备\n",
    " with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options,allow_soft_placement=True)) as sess:\n",
    " logger.info('========start inference============')\n",
    " # images = tf.placeholder(dtype=tf.float32, shape=[None, 64, 64, 1])\n",
    " # Pass a shadow label 0. This label will not affect the computation graph.\n",
    " graph = build_graph(top_k=3)\n",
    " saver = tf.train.Saver()\n",
    " # 自动获取最后一次保存的模型\n",
    " ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n",
    " if ckpt:\n",
    " saver.restore(sess, ckpt)\n",
    " val_list=[]\n",
    " idx_list=[]\n",
    " # 预测每一张图\n",
    " for item in image_set:\n",
    " temp_image = item\n",
    " predict_val, predict_index = sess.run([graph['predicted_val_top_k'], graph['predicted_index_top_k']],\n",
    " feed_dict={graph['images']: temp_image,\n",
    " graph['keep_prob']: 1.0,\n",
    " graph['is_training']: False})\n",
    " val_list.append(predict_val)\n",
    " idx_list.append(predict_index)\n",
    " #return predict_val, predict_index\n",
    " return val_list,idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    " print(FLAGS.mode)\n",
    " if FLAGS.mode == \"train\":\n",
    " train()\n",
    " elif FLAGS.mode == 'validation':\n",
    " dct = validation()\n",
    " result_file = 'result.dict'\n",
    " logger.info('Write result into {0}'.format(result_file))\n",
    " with open(result_file, 'wb') as f:\n",
    " pickle.dump(dct, f)\n",
    " logger.info('Write file ends')\n",
    " elif FLAGS.mode == 'inference':\n",
    " label_dict = get_label_dict()\n",
    " name_list = get_file_list('/home/test/tf_docker_share/Match/ID/testpic')\n",
    " # os.chdir(name_list)\n",
    " #binary_pic(name_list)\n",
    " #tmp_name_list = get_file_list('../data/tmp')\n",
    " # 将待预测的图片名字列表送入predict()进行预测，得到预测的结果及其index\n",
    " # for path in os.listdir(os.getcwd()):\n",
    " final_predict_val, final_predict_index = inference(name_list)\n",
    " final_reco_text =[] # 存储最后识别出来的文字串\n",
    " # 给出top 3预测，candidate1是概率最高的预测\n",
    " for i in range(len(final_predict_val)):\n",
    " candidate1 = final_predict_index[i][0][0]\n",
    " candidate2 = final_predict_index[i][0][1]\n",
    " candidate3 = final_predict_index[i][0][2]\n",
    " final_reco_text.append(label_dict[int(candidate1)])\n",
    " logger.info('[the result info] image: {0} predict: {1} {2} {3}; predict index {4} predict_val {5}'.format(name_list[i],\n",
    " label_dict[int(candidate1)],label_dict[int(candidate2)],label_dict[int(candidate3)],final_predict_index[i],final_predict_val[i]))\n",
    " print ('=====================OCR RESULT=======================\\n')\n",
    " # 打印出所有识别出来的结果（取top 1）\n",
    " for i in range(len(final_reco_text)):\n",
    " print(final_reco_text[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    " tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
